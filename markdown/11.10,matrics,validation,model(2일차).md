# 20 - 11 10

keras02. ~ 12

## 숙제 

#### 암기하자

- compile 파라미트 -> loss, matrics, optimizer
- fit 파라미터 -> x, y epochs



----

#### mode.compile(loss ='mse')

mse는 오차율을 줄이는 방식으로 두 점 사이의 거리의 차를 제곱하는 방식으로 음수가 발생하지 않음

#### MSA =  절대값

두 점 사이의 거리의 차를 절대 값으로 변환 

batch_size 

배치 가 높으면 속도가 빠르나 학습의 갯수가 작아진다. = 학습의 퀄리티가 낮아짐

ex) default = 32



acc가 1.0 이 나올 수 없었던 이유 

[[1.0000318]
 [1.9999561]
 [2.9999738]
 [3.999992 ]
 [5.00001  ]
 [6.000019 ]
 [7.000009 ]
 [7.9999995]
 [8.9999895]
 [9.999979 ]]

x에 대한 y 값을 구하면 

무한히 그 수에 수렴 하는 것이지 그 수가 아니다.  acc= 1은 그 수!


------

### 회귀모델 vs 분류모델(정리필요)

분류모델

- 입력된 값이 어느 대상에 속하는 것인가 확률적으로 구분하는 것 
- Ex) 입력 값이 욕설인가 아닌가 -> 욕설, 욕설이 아닌 데이터가 필요

회귀모델

- 결과가 float의 형태로 나타나는 모델
- Ex) 내일의 평균 주식 가격은 1000.0001원의 대표값은 => 1000원 인 것 뿐 실 가격은 1000.0001원이다. 



분류와 회귀의 정리

https://nexablue.tistory.com/entry/ML-%EB%B6%84%EB%A5%98Classification%EC%99%80-%ED%9A%8C%EA%B7%80Regression



회귀, 분류 모델의 종류

https://rk1993.tistory.com/entry/%EB%AA%A8%EB%8D%B8-%EC%84%B1%EB%8A%A5-%ED%8F%89%EA%B0%80-%EC%A7%80%ED%91%9C-%ED%9A%8C%EA%B7%80-%EB%AA%A8%EB%8D%B8-%EB%B6%84%EB%A5%98-%EB%AA%A8%EB%8D%B8



------



#### compile(metrics = ['acc'])란?

- loss는 오차율의 조정에 영향을 주지만 metric은 개발자가 참고 할 수 있는 보조적 지표이다. 

- metrics는 리스트를 매개변수로 받으며 복수의 보조 지표를 나타 낼 수 있다. Ex) ['acc','mse','msa']

- 이후 evaluate 시 반환되는 값도 acc, mse, msa와 같이 복수의 값을 반환한다.	
  - 평가에 사용되는 데이터는 트레이닝에 학습시켜서는 안된다.



RMSE 와 R^2

- RMSE
  - y_test와 predict( x_test)를 사용한 평가지표 y_test와 예상 결과물이 얼마나 유사한지 비교한다.
  - mse에 루트를 사용하여 얻는다.
  - sklearn.metrics 모듈의 mean_squeared_error(y_test, y_predict)를 사용하여 mse를 얻은 뒤 -> np.sqrt에 넣어 얻는다.

- R^2
  - 상관계수를 제곱하여 얻는 값(사실 무슨소린지 잘 모르겠음.)
  -  sklearn모듈의 r2_score를 사용하여 구하며 r2_score(y_test, y_predict)

- R^2는 1에 가까울 수록 RMSE는 0에 가까울 수록 높은 정확도를 보인다.
- 두 지표는 metrics 파라미터에 들어가는 msa,acc와 같이 개발자가 작성한 모델이 적합한 모델인지 판단(평가)하는 지표로 사용된다.

------

##### 모델의 모양(신경망의 모양) 

통상적으로 다이아몬드, 역삼각, 직사각형, 정사각형의 형태가 적합한 성능을 가진다.

------

#### Validation

- 훈련 데이터와 테스트 데이너만으로 훈련의 척도를 판단 할 수 있으나 과대적합이 발생 할 수 있다.

  - 과대적합: 훈련 데이터와 테스트 데이터가 너무 적합한 것으로 훈련된 데이터 외의 값에 대응하기 어려움

- 평가를 위한 데이터가 학습이 되어 있다면 정확한 데이터를 평가 할 수 없으므로 별도의 평가를 위한 데이터를 마련한다.

- 정제된 데이터 x의 80%는 학습 15%는 테스트 5%평가에 사용하는 방식으로 진행 할 수 있다.

  ##### train_test_split

  - 위와 같이 정제된 데이터 x를 편하게 나누며 특정 구간에서의 데이터의 쏠림 현상을 줄이는 suffle기능이 포함된 모듈
  - sklearn.moel_selection 모듈의 train_test_split이 있다.

  - x_train, x_test, y_tain, y_test = train_test_split(x, y, train_size = 0.8, shuffle=True) 
  - x_train, x_val, y_tain, y_val = train_test_split(x_train, y_train, train_size = 0.8, shuffle=True) 

통해 얻을 수 있으며 

- model.fit(x_train, y_train, epochs= 100, validation_date= (x_val, y_val))
- model.fit(x_train, y_train, epochs= 100, validation_split= 0.2) # train 값중 20%를 validation에 사용



------



##### 스칼라, 백터, 매트릭스,텐서

- shape로 확인이 가능

- 스칼라

  - [1,2,3,4,5,6].shape => (6,) => 6개의 요소를 가지고 있다. 저 하나의 요소를 스칼라라 한다

- 백터

  - [1,2,3,4,5,6] => (6,) 저 arry를 백터라 한다.
  - Ex) 날씨는 온도라는 속성만을 가진다.
  - [[1,2,3],[4,5,6]] => (2,3) =>2개의 데이터를 가지고있으며 각 데이터는 3개의 속성을 가진다.
  - Ex) 날씨 = 온도, 습도, 바람의 속성을 가진 하나의 데이터로 총 2개의 데이터 ex)2일의 데이터가 있다.

- 매트릭스(행렬)

  - [(집)

      [(사람)

    ​    [(사람1)

    (나이)1(키),2,(몸무게)3],

    ​    [(사람2)

    4,5,6]

      ],[(가구)

    ​    [7,8,9],

    ​    [10,11,12]

      ]

      ] 와 같은 형태로 

    집(가장 바깥 괄호)은 가구(다음안쪽 괄호 1)와 사람(안쪽괄호 2)으로 이루어지며  가구는 사람은 2개의 사람이 있으며 남자는 나이(1),2,3의 요소를 가진다.



------&nasp

mlp 멀티 레이어 퍼세트론