# 20 - 11 10

keras02. ~ 12

## 숙제 

#### 암기하자

- compile 파라미트 -> loss, matrics, optimizer
- fit 파라미터 -> x, y epochs



-----------
<br>

#### mode.compile(loss ='mse')

loss는 입력받은 x를 통해 예측된 y와 정답 y의 오차율을 의미
  - 낮을수록 좋은 값.
  - mse는 오차율을 구하거나 모델을 평가하는 수식
  - x와 y의 차를 제곱
  - 오차가 크면 클 수록 값이 커지는 특징이 있음.

#### mae =  평균 절대값 오차

mse와 같은 오차율을 구하거나 모델들 평가하는 수식
  - 측정값 - 실제값의 절대값


### batch_size 

한 번에 학습하는 데이터의 수 
  - 1000만개의 데이터, batch_size =1
    - 하나의 데이터 마다 w를 갱신
    - 낮은 배치는 속도가 느려짐
    - 높은 배치는 부족한 메모리로 인해 학습 실패
    - 디폴트 배치의 값= 32
    - Lager batches = Faster Training



acc가 1.0 이 나올 수 없었던 이유 

[[1.0000318]
 [1.9999561]
 [2.9999738]
 [3.999992 ]
 [5.00001  ]
 [6.000019 ]
 [7.000009 ]
 [7.9999995]
 [8.9999895]
 [9.999979 ]]

acc는 분류모델에서 사용되는 평가 수식으로 다중분류 즉 명확한 답이 나온다. 그러나 mse의 경우 결과가 실수로 반환되기 때문에 1에 가까워 질 수 있으나 1이 나오기 위해선 정수 값으로 나타냐야한다.


------
<br>

### 회귀모델 vs 분류모델(정리필요)

분류모델

- 입력된 값이 어느 대상에 속하는 것인가 확률적으로 구분하는 것 
- 다중분류 모델 vs 이분 분류 모델
  - 이분 분류 모델: 결과의 종류가 2개
  - 다중 분류 모델: 결과의 종류가 2개 이상
- Ex) 손으로 적은 숫자 0~9를 인식하여 0~9 숫자와 매칭
  - 아무리 큰 숫자도 0~9로 표현 할 수 있다.

회귀모델

- 결과가 float의 형태로 나타나는 모델
- Ex) 회귀 모델을 통해 얻은 값이 1000.01원이 나온 것은 회귀 모델이며 대표값이 1000원일 뿐 값 자체는 1000.01원 이다.



분류와 회귀의 정리

https://nexablue.tistory.com/entry/ML-%EB%B6%84%EB%A5%98Classification%EC%99%80-%ED%9A%8C%EA%B7%80Regression



회귀, 분류 모델의 종류

https://rk1993.tistory.com/entry/%EB%AA%A8%EB%8D%B8-%EC%84%B1%EB%8A%A5-%ED%8F%89%EA%B0%80-%EC%A7%80%ED%91%9C-%ED%9A%8C%EA%B7%80-%EB%AA%A8%EB%8D%B8-%EB%B6%84%EB%A5%98-%EB%AA%A8%EB%8D%B8



------
<br>



#### compile(metrics = ['acc'])란?

<a href='https://github.com/Kmmanki/bit_seoul/blob/main/keras/keras04_metrics2.py'>keras04_metrics2.py</a>

- metrics는 개발자가 참고 하는 지표
  - loss에 영향을 주지 않는다.

- metrics는 리스트를 매개변수로 받으며 복수의 보조 지표를 나타 낼 수 있다. 
  - Ex) ['acc','mse','msa']

- 이후 evaluate 시 반환되는 값도 acc, mse, msa와 같이 복수의 값을 반환한다.	
  - 평가에 사용되는 데이터는 트레이닝에 학습시켜서는 안된다.



RMSE 와 R^2
<a href='https://github.com/Kmmanki/bit_seoul/blob/main/keras/keras07_R2.py'>keras07_R2.py</a>
- RMSE
  - y_test와 predict( x_test)를 사용한 평가지표 y_test와 예상 결과물이 얼마나 유사한지 비교한다.
  - mse에 루트를 사용하여 얻는다.
  - sklearn.metrics 모듈의 mean_squeared_error(y_test, y_predict)를 사용하여 mse를 얻은 뒤 -> np.sqrt에 넣어 얻는다.

- R^2
  - 상관계수를 제곱하여 얻는 값(사실 잘 모르겠음.)
  -  sklearn모듈의 r2_score를 사용하여 구하며 r2_score(y_test, y_predict)

- R^2는 1에 가까울 수록 RMSE는 0에 가까울 수록 높은 정확도를 보인다.
- 두 지표는 metrics 파라미터에 들어가는 msa,acc와 같이 개발자가 작성한 모델이 적합한 모델인지 판단(평가)하는 지표로 사용된다.

------
&nasp;
##### 모델의 모양(신경망의 모양) 

통상적으로 다이아몬드, 역삼각, 직사각형, 정사각형의 형태가 적합한 성능을 가진다.

------
<br>

#### Validation

<a href='https://github.com/Kmmanki/bit_seoul/blob/main/keras/keras07_val.py'>keras09_val.py</a>

<a href='https://github.com/Kmmanki/bit_seoul/blob/main/keras/keras11_train_test_split2.py'>keras11_train_test_split2.py</a>

- 훈련의 성능을 측정하는 척도로 testset과의 차이점은 test set의 경우 모델의 최종 성능을 측정하는 데이터이며 validation set은 학습 시 사용되는 지표로 각 epoches마다 사용되며 vailidation set은 학습에 관여하며 test set은 학습에 관여하지 않는다.


- 정제된 데이터 x의 80%는 학습 15%는 테스트 5%평가에 사용하는 방식으로 진행 할 수 있다.

  ##### train_test_split

  - 위와 같이 정제된 데이터 x를 나누며 특정 구간에서의 데이터의 쏠림 현상을 줄이는 suffle기능이 포함된 모듈
  - sklearn.moel_selection 모듈의 train_test_split이 있다.

  - x_train, x_test, y_tain, y_test = train_test_split(x, y, train_size = 0.8, shuffle=True) 
  - x_train, x_val, y_tain, y_val = train_test_split(x_train, y_train, train_size = 0.8, shuffle=True) 


- model.fit(x_train, y_train, epochs= 100, validation_date= (x_val, y_val))
- model.fit(x_train, y_train, epochs= 100, validation_split= 0.2) # train 값중 20%를 validation에 사용

------
<br>

##### 스칼라, 백터, 매트릭스,텐서

- shape로 확인이 가능

- 스칼라

  - [1,2,3,4,5,6].shape => (6,) => 6개의 요소를 가지고 있다. 저 하나의 요소를 스칼라라 한다

- 백터

  - [1,2,3,4,5,6] => (6,) arry를 백터라 한다.
  - Ex) 날씨는 온도라는 속성만을 가진다.
  - [[1,2,3],[4,5,6]] => (2,3) =>2개의 데이터를 가지고있으며 각 데이터는 3개의 속성을 가진다.
  - Ex) 날씨 = 온도, 습도, 바람의 속성을 가진 하나의 데이터로 총 2개의 데이터 ex)2일의 데이터가 있다.

- 매트릭스(행렬)

  - [(집)

      [(사람)

    ​    [(사람1)

    (나이)1(키),2,(몸무게)3],

    ​    [(사람2)

    4,5,6]

      ],[(가구)

    ​    [7,8,9],

    ​    [10,11,12]

      ]

      ] 와 같은 형태로 

    집(가장 바깥 괄호)은 가구(다음안쪽 괄호 1)와 사람(안쪽괄호 2)으로 이루어지며  가구는 사람은 2개의 사람이 있으며 남자는 나이(1),2,3의 요소를 가진다.
<br>
<a href='https://github.com/Kmmanki/bit_seoul/blob/main/keras/keras12_mip.py'>전치행렬(행과 열의 변환)</a>

------
<br>

### perceptrons
다수의 신호(inpus)을 받아 하나의 신호(output)을 반환
 - 그래프의 직선 형태만 추측 할 수 있는 모델
 - 이를 보안하기위해 multi layer perceptrons이 만들어짐
 - mlp = 복수의 hidden layer로 구성


### 과적합
모델의 구조가 train set에만 최적화 되어 train set의 값은 정확하게 구분하지만 다른 data set은 구분 하지 못하는 상태

