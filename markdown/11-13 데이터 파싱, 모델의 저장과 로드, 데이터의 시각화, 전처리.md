# 11-13



---------------

키워드

데이터 파싱, 모델의 저장과 로드, 데이터의 시각화, 전처리

과제 

Sandard Scaler ,RobustScaler, MaxAbs Scaler 정리, 
load 모델의 Input_shape 수정하여 레이어 추가(keras)

## 전일 복습

|       | shape | inputs_shape               |
| ----- | ----- | -------------------------- |
| Dense | 2     | (?)                        |
| LSTM  | 3     | (?,?)                      |
| CNN   | 4     | (?,?,?) -> 가로, 세로 픽셀 |

시계열의 데이터는 Y값이 없다. 

- x의 5일 값을 가져와 학습하고 x6일의 값이 Y값이 된다.

`[1,2,3,4,5,6,7,8,9,10]`

x= [[1,2,3,4,5],[2,3,4,5,6],[3,4,5,6,7]....]

y= [6,7,8,9 ....]



### 데이터 파싱  
<a href='https://github.com/Kmmanki/bit_seoul/blob/main/keras/keras27_Dense_split.py'>keras 27</a>

<br>

------

<br>

### 모델의 저장 <a href='https://github.com/Kmmanki/bit_seoul/blob/main/keras/keras28_save.py'>keras 28 ~ 31</a>
model.save()

from tensorflow.keras.models import load_model

mode = load_model(".\save\keras27.h5")

모델 로드 시 레이어의 네이밍이 겹치면 에러가 발생

```
from tensorflow.keras.models import model_from_json
model = load_model('./save/keras26_model.h5')
model.summary()
model(Input(shape=(4,1), name='input1'))
model.add(Dense(1, name='output1'))
model.summary()
```
**model에 새로운 Input 객체를 설정해주면된다.**



<br>

------

<br>

### 데이터의 시각화 <a href='https://github.com/Kmmanki/bit_seoul/blob/main/keras/keras32_hist.py'>keras 32</a>

cmd에서 그래프 폴더로 이동 

```
d:
cd Study
cd graph
tensorboard --logdir=.
```

주소로 이동 http://localhost:6006/

<br>

------

<br>

### 전처리<a href='https://github.com/Kmmanki/bit_seoul/blob/main/keras/keras34_minmax.py'>keras34_minmax</a>

|           | x                                 | y         |
| :-------- | --------------------------------- | --------- |
| train     | 전처리 O<br />fit(), transform(x) | 전처리 X  |
| val       | transform(x)                      | 전처리 X  |
| test      | transform(x)                      | 전처리 X  |
| predicate | transform(x)                      | 값이 없음 |

<br>

#### MinMax Scaler

데이터의 값을 0 ~ 1으로 만들어서 데이터의 처리를 속도 향상

그러나 학습된 데이터의 최소, 최대의 값을 입력 받으면 오차율 증가 **x - min / max -min**

ps. 각 행이 아닌 열 마다 계산 / 즉 같은 속성 끼리 비교 [1,2,3],[4,5,6] 이라면 1과 4 최소 최대를 찾아 연산 2와 5를 찾아연산

```
from sklearn.preprocessing import MinMaxScaler
minMaxScaler = MinMaxScaler()
minMaxScaler.fit(x)
x = minMaxScaler.transform(x)
x_predict = minMaxScaler.transform(x_predict)
```

#### Standard Scaler

평균을 제거하고 데이터를 단위 분산으로 조정

이상치가 있다면 평균과 표준편차에 영향을 미쳐 변환된 데이터의 확산은 매우 달라짐

```
from sklearn.preprocessing import StandardScaler
standardScaler = StandardScaler()
standardScaler.fit(x)
x = standardScaler.transform(x)
```

<br>

#### MaxAbsScaler

절대값이 0~1사이에 매핑

 양수 데이터로만 구성된 특징 데이터셋에서는 MinMaxScaler와 유사하게 동작, 큰 이상치에 민감

```
from sklearn.preprocessing import MaxAbsScaler
maxAbsScaler = MaxAbsScaler()
maxAbsScaler.fit(x)
x = maxAbsScaler.transform(x)
```

<br>

#### Robust Scaler

아웃라이어의 영향을 최소화한 기법이다. `중앙값(median)과 IQR(interquartile range)`을 사용하기 때문에 StandardScaler와 비교해보면 **표준화 후 동일한 값을 더 넓게 분포** 시키고 있음을 확인 할 수 있다.

***IQR = Q3 - Q1 : 즉, 25퍼센타일과 75퍼센타일의 값들을 다룬다.\***

```
from sklearn.preprocessing import RobustScaler
robustScaler = RobustScaler()
robustScaler.fit(x)
x = robustScaler.transform(train_data)
```